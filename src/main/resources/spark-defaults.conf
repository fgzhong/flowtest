spark.authenticate=false
spark.shuffle.service.enabled=true
spark.shuffle.service.port=7337
#spark.driver.bindAddress=127.0.0.1
#spark.driver.bindAddress=192.168.1.90
#spark.driver.host=120.78.71.31
spark.driver.port=5602
#spark.ui.port=4040
spark.ui.enabled=true
spark.io.encryption.enabled=false
spark.network.crypto.enabled=false
spark.ui.killEnabled=true
spark.lineage.log.dir=/var/log/spark2/lineage

spark.eventLog.enabled=true
spark.eventLog.dir=hdfs://nameservice1/user/spark/spark2ApplicationHistory
spark.yarn.historyServer.address=http://dn1.ali.szol.bds.com:18089
#spark.yarn.historyServer.allowTracking=true
spark.history.fs.logDirectory=hdfs://nameservice1/user/spark/spark2ApplicationHistory
spark.driver.extraLibraryPath=/opt/cloudera/parcels/CDH-5.15.1-1.cdh5.15.1.p0.4/lib/hadoop/lib/native
spark.executor.extraLibraryPath=/opt/cloudera/parcels/CDH-5.15.1-1.cdh5.15.1.p0.4/lib/hadoop/lib/native
spark.yarn.am.extraLibraryPath=/opt/cloudera/parcels/CDH-5.15.1-1.cdh5.15.1.p0.4/lib/hadoop/lib/native
spark.yarn.archive=hdfs://nameservice1/user/maplecloudy/mypro/bin

spark.default.parallelism=1000
spark.sql.shuffle.partitions=1000
spark.master=yarn
spark.submit.deployMode=client
spark.yarn.am.memory=2048m
spark.yarn.am.cores=2
spark.executor.instances=9
spark.executor.memory=16g
spark.executor.cores=4
#spark.task.cpus=1
spark.yarn.executor.memoryOverhead=4096
#spark.driver.extraJavaOptions=-XX:MaxDirectMemorySize=2048m
#spark.executor.extraJavaOptions=-XX:MaxDirectMemorySize=4096m
spark.kryoserializer.buffer.max=1024m
spark.kryoserializer.buffer=4m

spark.shuffle.compress=true
spark.io.compression.codec=lz4
spark.serializer=org.apache.spark.serializer.KryoSerializer

spark.yarn.appMasterEnv.PYSPARK_PYTHON=/usr/lib64/python2.7


